{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Inference and Validation\n",
    "\n",
    "After having created a network, it has to be used for making predictions (generally called inference). Generally, neural networks perform very good on the training dataset, but perform poorly on the testing set. This is called **overfitting**. For measuring the overfitting, we use an unseen data called **validation set**. To *avoid overfitting* **regularization methods** are used, such as **dropout** while monitoring the validation performance during training.  \n",
    "Generally, the 10-20% of the dataset is taken away for validation and testing purposes, and the other part is for training."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "# After the first download, we put @download=False@\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('.\\\\F_MNIST_data\\\\', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('.\\\\F_MNIST_data\\\\', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "cannot import name 'F' from 'torch.nn.functional' (C:\\Users\\sferro\\ProjectsCode\\PHD-IIT\\PyScripts\\CTCHandwritingDocuments\\env\\lib\\site-packages\\torch\\nn\\functional.py)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ca6b4a54fa99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'F' from 'torch.nn.functional' (C:\\Users\\sferro\\ProjectsCode\\PHD-IIT\\PyScripts\\CTCHandwritingDocuments\\env\\lib\\site-packages\\torch\\nn\\functional.py)"
     ]
    }
   ],
   "source": [
    "from torch import nn, optim\n",
    "from torch.nn.functional import F\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # we have to put here all the functions which can be useful\n",
    "        self.fc1 = nn.Linear(784,256)\n",
    "        self.fc2 = nn.Linear(256,128)\n",
    "        self.fc3 = nn.Linear(128,64)\n",
    "        self.fc4 = nn.Linear(64,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        \n",
    "        x = F.relu(self.fc1())\n",
    "        x = F.relu(self.fc2())\n",
    "        x = F.relu(self.fc3())\n",
    "        x = F.log_softmax(self.fc4(), dim=1)\n",
    "        return x"
   ]
  },
  {
   "source": [
    "The goal of the validation is to measure the model's performances on images which weren't seen by the model during training.  \n",
    "The measures to compute the performances can be:\n",
    "- accuracy\n",
    "- precision\n",
    "- recall\n",
    "- top-5 error rate\n",
    "\n",
    "We will use the accuracy.  \n",
    "Now, we do a forward pass on a batch of the test set."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.003)\n",
    "\n",
    "for images,labels in testloader:\n",
    "    # the images are already flattened in the forward method\n",
    "    # so, we don't have to flatten them anymore\n",
    "    logps = model(images)\n",
    "    ps = torch.exp(logps)\n",
    "    # let's see if the probabilities over the classses sum up to 1\n",
    "    print(f\"The probabilities over the classes sum up to {torch.sum(ps)}\")\n",
    "    print(logps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}